{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('train_features.pk', 'rb') as fin_train_features:\n",
    "    with open('train_scores.pk', 'rb') as fin_train_scores:\n",
    "        # encoding='latin1' is because the pickle file was dumped using Python2 \n",
    "        # and now we're loading it in Python3.\n",
    "        train_features = pickle.load(fin_train_features, encoding='latin1') \n",
    "        train_scores = pickle.load(fin_train_scores, encoding='latin1')\n",
    "        \n",
    "with open('test_features.pk', 'rb') as fin_test_features:\n",
    "    with open('test_scores.pk', 'rb') as fin_test_scores:\n",
    "        # encoding='latin1' is because the pickle file was dumped using Python2 \n",
    "        # and now we're loading it in Python3.\n",
    "        test_features = pickle.load(fin_test_features, encoding='latin1') \n",
    "        test_scores = pickle.load(fin_test_scores, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.00000000e+00   1.18000000e+03   1.34000000e+03]\n",
      " [  1.00000000e+00   2.57000000e+03   1.69000000e+03]\n",
      " [  1.00000000e+00   7.70000000e+02   2.72000000e+03]\n",
      " ..., \n",
      " [  1.00000000e+00   1.53000000e+03   1.53000000e+03]\n",
      " [  1.00000000e+00   1.60000000e+03   1.41000000e+03]\n",
      " [  1.00000000e+00   1.02000000e+03   1.02000000e+03]]\n",
      "[[  1.00000000e+00   1.43000000e+03   1.78000000e+03]\n",
      " [  1.00000000e+00   2.95000000e+03   2.14000000e+03]\n",
      " [  1.00000000e+00   1.71000000e+03   1.03000000e+03]\n",
      " ..., \n",
      " [  1.00000000e+00   2.52000000e+03   2.52000000e+03]\n",
      " [  1.00000000e+00   2.31000000e+03   1.83000000e+03]\n",
      " [  1.00000000e+00   1.02000000e+03   1.02000000e+03]]\n"
     ]
    }
   ],
   "source": [
    "print (train_features)\n",
    "print (test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 221900.  538000.  180000. ...,  360000.  400000.  325000.]\n",
      "[ 310000.  650000.  233000. ...,  610685.  400000.  402101.]\n"
     ]
    }
   ],
   "source": [
    "print (train_scores)\n",
    "print (test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial_weights = np.array([-100000., 1., 1.])\n",
    "step_size = 4e-12\n",
    "tolerance = 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance):\n",
    "    converged = False \n",
    "    weights = np.array(initial_weights) # make sure it's a numpy array\n",
    "    while not converged:\n",
    "        # compute the predictions based on feature_matrix and weights using your predict_output() function\n",
    "        predictions = [np.dot(row, weights) for row in feature_matrix]\n",
    "        # compute the errors as predictions - output\n",
    "        errors = predictions - output\n",
    "        gradient_sum_squares = 0 # initialize the gradient sum of squares\n",
    "        # while we haven't reached the tolerance yet, update each feature's weight\n",
    "        for i in range(len(weights)): # loop over each weight\n",
    "            # Recall that feature_matrix[:, i] is the feature column associated with weights[i]\n",
    "            # compute the derivative for weight[i]:\n",
    "            derivative = 2 * feature_matrix[:, i].dot(errors)\n",
    "            # add the squared value of the derivative to the gradient magnitude (for assessing convergence)\n",
    "            gradient_sum_squares += (derivative * derivative)\n",
    "            # subtract the step size times the derivative from the current weight\n",
    "            weights[i] -= (step_size * derivative)\n",
    "        # compute the square-root of the gradient sum of squares to get the gradient matnigude:\n",
    "        gradient_magnitude = sqrt(gradient_sum_squares)\n",
    "        if gradient_magnitude < tolerance:\n",
    "            converged = True\n",
    "        print (gradient_magnitude)\n",
    "    return(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73072020548860.52\n",
      "22673220965110.355\n",
      "7060794582096.968\n",
      "2275682394265.5166\n",
      "928984105638.4122\n",
      "656307425178.0717\n",
      "610615351821.313\n",
      "593078765306.8464\n",
      "578705920128.3191\n",
      "564945676163.1862\n",
      "551538681424.557\n",
      "538452422879.05133\n",
      "525676912708.20874\n",
      "513204543689.9769\n",
      "501028100319.0722\n",
      "489140559100.83386\n",
      "477535065232.9939\n",
      "466204926754.44226\n",
      "455143610499.4318\n",
      "444344738312.005\n",
      "433802083366.417\n",
      "423509566576.4528\n",
      "413461253090.1034\n",
      "403651348867.41534\n",
      "394074197339.5448\n",
      "384724276147.07697\n",
      "375596193955.73285\n",
      "366684687347.62866\n",
      "357984617786.2924\n",
      "349490968653.69214\n",
      "341198842357.5615\n",
      "333103457507.3601\n",
      "325200146157.2359\n",
      "317484351114.4039\n",
      "309951623311.386\n",
      "302597619240.5971\n",
      "295418098449.8005\n",
      "288408921096.98505\n",
      "281566045563.26013\n",
      "274885526122.38104\n",
      "268363510665.57315\n",
      "261996238480.33713\n",
      "255780038081.95294\n",
      "249711325096.4341\n",
      "243786600193.71393\n",
      "238002447069.86923\n",
      "232355530477.21387\n",
      "226842594301.13904\n",
      "221460459682.57397\n",
      "216206023185.00217\n",
      "211076255004.9607\n",
      "206068197225.00232\n",
      "201178962108.10352\n",
      "196405730432.5474\n",
      "191745749866.3071\n",
      "187196333379.99927\n",
      "182754857697.49725\n",
      "178418761783.30173\n",
      "174185545365.79962\n",
      "170052767495.56363\n",
      "166018045137.85513\n",
      "162079051798.52515\n",
      "158233516182.51367\n",
      "154479220884.18103\n",
      "150814001108.70923\n",
      "147235743423.8463\n",
      "143742384541.2569\n",
      "140331910126.79987\n",
      "137002353639.0207\n",
      "133751795195.20964\n",
      "130578360464.3643\n",
      "127480219586.41537\n",
      "124455586117.09543\n",
      "121502715997.84215\n",
      "118619906550.14531\n",
      "115805495493.74794\n",
      "113057859988.1491\n",
      "110375415696.83931\n",
      "107756615873.75085\n",
      "105199950471.36763\n",
      "102703945270.01134\n",
      "100267161027.77435\n",
      "97888192650.63171\n",
      "95565668382.23299\n",
      "93298249012.92732\n",
      "91084627107.54704\n",
      "88923526251.52248\n",
      "86813700314.86891\n",
      "84753932733.6561\n",
      "82743035808.50656\n",
      "80779850019.7524\n",
      "78863243358.83086\n",
      "76992110675.55324\n",
      "75165373040.84715\n",
      "73381977124.63596\n",
      "71640894588.46043\n",
      "69941121492.52684\n",
      "68281677716.813995\n",
      "66661606395.918236\n",
      "65079973367.308784\n",
      "63535866632.67203\n",
      "62028395832.03539\n",
      "60556691730.37232\n",
      "59119905716.38351\n",
      "57717209313.17213\n",
      "56347793700.53073\n",
      "55010869248.55996\n",
      "53705665062.35236\n",
      "52431428537.483345\n",
      "51187424926.04096\n",
      "49972936912.96381\n",
      "48787264202.416214\n",
      "47629723113.99113\n",
      "46499646188.4875\n",
      "45396381803.03511\n",
      "44319293795.363655\n",
      "43267761096.97615\n",
      "42241177375.032036\n",
      "41238950682.72112\n",
      "40260503117.94223\n",
      "39305270490.06781\n",
      "38372701994.62546\n",
      "37462259895.692764\n",
      "36573419215.82911\n",
      "35705667433.36401\n",
      "34858504186.868904\n",
      "34031440986.63769\n",
      "33224000933.01711\n",
      "32435718441.414364\n",
      "31666138973.83681\n",
      "30914818776.794025\n",
      "30181324625.422043\n",
      "29465233573.679527\n",
      "28766132710.466995\n",
      "28083618921.53657\n",
      "27417298657.04928\n",
      "26766787704.644604\n",
      "26131710967.900024\n",
      "25511702250.041912\n",
      "24906404042.78751\n",
      "24315467320.20466\n",
      "23738551337.451412\n",
      "23175323434.30069\n",
      "22625458843.31951\n",
      "22088640502.603985\n",
      "21564558872.953922\n",
      "21052911759.38922\n",
      "20553404136.896236\n",
      "20065747980.312412\n",
      "19589662098.24726\n",
      "19124871970.93866\n",
      "18671109591.9624\n",
      "18228113313.693672\n",
      "17795627696.43824\n",
      "17373403361.136456\n",
      "16961196845.575056\n",
      "16558770463.993332\n",
      "16165892170.035147\n",
      "15782335422.944761\n",
      "15407879056.939611\n",
      "15042307153.682022\n",
      "14685408917.775837\n",
      "14336978555.2211\n",
      "13996815154.744915\n",
      "13664722571.957497\n",
      "13340509316.245537\n",
      "13023988440.36207\n",
      "12714977432.623976\n",
      "12413298111.67498\n",
      "12118776523.74351\n",
      "11831242842.334208\n",
      "11550531270.308807\n",
      "11276479944.27807\n",
      "11008930841.273159\n",
      "10747729687.625614\n",
      "10492725870.008085\n",
      "10243772348.590559\n",
      "10000725572.253323\n",
      "9763445395.814184\n",
      "9531794999.215723\n",
      "9305640808.63421\n",
      "9084852419.459099\n",
      "8869302521.096733\n",
      "8658866823.5627\n",
      "8453423985.815262\n",
      "8252855545.783617\n",
      "8057045852.065504\n",
      "7865881997.236956\n",
      "7679253752.748549\n",
      "7497053505.367794\n",
      "7319176195.124644\n",
      "7145519254.732477\n",
      "6975982550.447833\n",
      "6810468324.329412\n",
      "6648881137.870606\n",
      "6491127816.965482\n",
      "6337117398.186923\n",
      "6186761076.331178\n",
      "6039972153.212977\n",
      "5896665987.67604\n",
      "5756759946.783843\n",
      "5620173358.17333\n",
      "5486827463.537842\n",
      "5356645373.214816\n",
      "5229552021.847728\n",
      "5105474125.102723\n",
      "4984340137.412679\n",
      "4866080210.721546\n",
      "4750626154.208921\n",
      "4637911394.969769\n",
      "4527870939.627846\n",
      "4420441336.859356\n",
      "4315560640.806031\n",
      "4213168375.353861\n",
      "4113205499.2636094\n",
      "4015614372.127253\n",
      "3920338721.1288004\n",
      "3827323608.599409\n",
      "3736515400.3358607\n",
      "3647861734.6771817\n",
      "3561311492.31069\n",
      "3476814766.7954807\n",
      "3394322835.7845674\n",
      "3313788132.9357533\n",
      "3235164220.475398\n",
      "3158405762.4297185\n",
      "3083468498.477696\n",
      "3010309218.4324822\n",
      "2938885737.32578\n",
      "2869156871.082669\n",
      "2801082412.771413\n",
      "2734623109.4238567\n",
      "2669740639.400702\n",
      "2606397590.2912602\n",
      "2544557437.343257\n",
      "2484184522.4026537\n",
      "2425244033.350529\n",
      "2367701984.030908\n",
      "2311525194.6533604\n",
      "2256681272.661874\n",
      "2203138594.055781\n",
      "2150866285.153467\n",
      "2099834204.7940168\n",
      "2050012926.9527562\n",
      "2001373723.7783213\n",
      "1953888549.0206873\n",
      "1907530021.867196\n",
      "1862271411.1503508\n",
      "1818086619.933041\n",
      "1774950170.46166\n",
      "1732837189.4778833\n",
      "1691723393.87188\n",
      "1651585076.6834972\n",
      "1612399093.429302\n",
      "1574142848.760243\n",
      "1536794283.4321373\n",
      "1500331861.5837014\n",
      "1464734558.3204029\n",
      "1429981847.591222\n",
      "1396053690.3520947\n",
      "1362930523.0129216\n",
      "1330593246.1520007\n",
      "1299023213.5101917\n",
      "1268202221.2323477\n",
      "1238112497.3767369\n",
      "1208736691.660391\n",
      "1180057865.46233\n",
      "1152059482.0490136\n",
      "1124725397.0458364\n",
      "1098039849.1221676\n",
      "1071987450.9069812\n",
      "1046553180.1142557\n",
      "1021722370.8832855\n",
      "997480705.3165356\n"
     ]
    }
   ],
   "source": [
    "weights = regression_gradient_descent(train_features, train_scores, initial_weights, step_size, tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = [np.dot(row, weights) for row in test_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[366651.41203655908, 762662.39786164218, 386312.09499711636, 636989.65043403371, 269618.02636177395]\n",
      "[ 310000.  650000.  233000.  580500.  535000.]\n"
     ]
    }
   ],
   "source": [
    "print (predictions[:5])\n",
    "print (test_scores[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.70263446465e+14\n"
     ]
    }
   ],
   "source": [
    "residual = predictions - test_scores\n",
    "residual_sum_of_squares = sum(residual * residual)\n",
    "print (residual_sum_of_squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
